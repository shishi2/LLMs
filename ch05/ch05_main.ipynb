{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 无标记数据的预训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.4.3\n",
      "numpy version: 1.22.4\n",
      "tiktoken version: 0.7.0\n",
      "torch version: 2.4.1\n",
      "tensorflow version: 2.13.1\n",
      "2.4.1+cu121\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\", \n",
    "\t\t\"numpy\", \n",
    "\t\t\"tiktoken\", \n",
    "\t\t\"torch\",\n",
    "\t\t\"tensorflow\" # For OpenAI's pretrained weights\n",
    "\t\t]\n",
    "for p in pkgs:\n",
    "\tprint(f\"{p} version: {version(p)}\")\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Evaluating generative text models\n",
    "\n",
    "#### 5.1.1 GPT生成文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 未有k v cache\n",
    "\n",
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "\t\"vocab_size\": 50257,   # Vocabulary size\n",
    "\t\"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "\t\"emb_dim\": 768,        # Embedding dimension\n",
    "\t\"n_heads\": 12,         # Number of attention heads\n",
    "\t\"n_layers\": 12,        # Number of layers\n",
    "\t\"drop_rate\": 0.1,      # Dropout rate\n",
    "\t\"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference\t# 全局影响 可影响其他cell model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "\tencoded = tokenizer.encode(text, allowed_special={\"<|endoftext|\"})\n",
    "\tencoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "\treturn encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "\tflat = token_ids.squeeze(0)\n",
    "\treturn tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "\tmodel=model,\n",
    "\tidx=text_to_token_ids(start_context, tokenizer),\n",
    "\tmax_new_tokens=10,\n",
    "\tcontext_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 loss 交叉熵 perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "\t\t\t\t\t\t[40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "\t\t\t\t\t\t[1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "# 通过model + softmax -> 概率\n",
    "with torch.no_grad():\n",
    "\tlogits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)\n",
    "# 每个batch 中的 context_length 对应的50257为词表大小 其数值为对应该词的概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将概率转回文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs batch 1: every effort moves\n",
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Inputs batch 1: {token_ids_to_text(inputs[0], tokenizer)}\")\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n",
      "torch.Size([3, 50257])\n",
      "torch.Size([3, 50257])\n",
      "torch.Size([3, 50257])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "# target_probas_1 = probas[text_idx, :, targets[text_idx]]\t# :会进行广播 导致结果为3*3 对每个词表概率都取了targets[text_idx]的三个值\n",
    "\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)\n",
    "\n",
    "a = probas[text_idx]\n",
    "print(a.shape)\n",
    "b = a[[0,1,2]]\n",
    "print(b.shape)\n",
    "c = a[:]\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 目标是令以上三值达到1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n",
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "# 取对数\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)\n",
    "\n",
    "# 求平均\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 目标变为 令平均对数的值尽可能的大 上限为0\n",
    "\n",
    "- *-1 变为尽可能小 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 交叉熵 流程\n",
    "\n",
    "model+softmax求概率 $\\rightarrow$ 取出目标的概率 $\\rightarrow$ 取对数 $\\rightarrow$ 求平均 $\\rightarrow$ *-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 困惑度 exponential\n",
    "\n",
    "- perplexity = exp(交叉熵)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.3 training validation set loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"../ch02/the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "\twith urllib.request.urlopen(url) as response:\n",
    "\t\ttext_data = response.read().decode('utf-8')\n",
    "\twith open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "\t\tfile.write(text_data)\n",
    "else:\n",
    "\twith open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "\t\ttext_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n",
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "# First 99 characters\n",
    "print(text_data[:99])\n",
    "# Last 99 characters\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)           # 设置CPU随机种子\n",
    "torch.cuda.manual_seed(123)      # 设置当前GPU随机种子\n",
    "torch.cuda.manual_seed_all(123)  # 设置所有GPU随机种子（多卡时）\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "\ttrain_data,\n",
    "\tbatch_size=2,\n",
    "\tmax_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "\tstride=GPT_CONFIG_124M[\"context_length\"],\n",
    "\tdrop_last=True,\n",
    "\tshuffle=True,\n",
    "\tnum_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "\tval_data,\n",
    "\tbatch_size=2,\n",
    "\tmax_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "\tstride=GPT_CONFIG_124M[\"context_length\"],\n",
    "\tdrop_last=False,\n",
    "\tshuffle=False,\n",
    "\tnum_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "\tprint(\"Not enough tokens for the training loader. \"\n",
    "\t\t  \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "\t\t  \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "\tprint(\"Not enough tokens for the validation loader. \"\n",
    "\t\t  \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "\t\t  \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "\tprint(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "\tprint(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "\ttrain_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "\tval_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "\t\"\"\"\n",
    "\t计算给定批次的交叉熵\n",
    "\t\"\"\"\n",
    "\tinput_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\tlogits = model(input_batch)\n",
    "\tloss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "\treturn loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "\ttotal_loss=0.\n",
    "\tif len(data_loader) == 0:\n",
    "\t\treturn float(\"nan\")\n",
    "\t\n",
    "\tif num_batches is None:\n",
    "\t\tnum_batches = len(data_loader)\n",
    "\telse:\t# 防止batch的量比所有数量都多\n",
    "\t\tnum_batches = min(num_batches, len(data_loader))\n",
    "\t\n",
    "\tfor i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "\t\tif i >= num_batches:\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tloss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "\t\ttotal_loss += loss.item()\n",
    "\n",
    "\treturn total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98758273654514\n",
      "Validation loss: 10.981104850769043\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "\ttrain_loss = calc_loss_loader(train_loader, model, device)\n",
    "\tval_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Training a LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, \n",
    "\t\t\t\t\t\teval_freq, eval_iter, start_context, tokenizer):\n",
    "\ttrain_losses, val_losses, track_tokens_seen = [], [], []\n",
    "\ttokens_seen, global_step = 0, -1\n",
    "\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\tmodel.train()\n",
    "\n",
    "\t\tfor input_batch, target_batch in train_loader:\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tloss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\ttokens_seen += input_batch.numel()\t# 已训练的token计数\n",
    "\t\t\tglobal_step += 1\n",
    "\n",
    "\t\t\t# Optional evaluation step\n",
    "\t\t\tif global_step % eval_freq == 0:\n",
    "\t\t\t\ttrain_loss, val_loss = evaluate_model(\n",
    "\t\t\t\t\tmodel, train_loader, val_loader, device, eval_iter\n",
    "\t\t\t\t)\n",
    "\t\t\t\ttrain_losses.append(train_loss)\n",
    "\t\t\t\tval_losses.append(val_loss)\n",
    "\t\t\t\ttrack_tokens_seen.append(tokens_seen)\n",
    "\t\t\t\tprint(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "\t\t\t\t\t\tf\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\t\n",
    "\t\t# 每个epoch之后打印示例文本\n",
    "\t\tgenerate_and_print_sample(\n",
    "\t\t\tmodel, tokenizer, device, start_context\n",
    "\t\t)\n",
    "\n",
    "\treturn train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "\tmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\ttrain_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "\t\tval_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "\tmodel.train()\n",
    "\treturn train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "\tmodel.eval()\n",
    "\tcontext_size = model.pos_emb.weight.shape[0]\n",
    "\tencoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "\twith torch.no_grad():\n",
    "\t\ttoken_ids = generate_text_simple(\n",
    "\t\t\tmodel=model, idx=encoded, max_new_tokens=50, context_size=context_size\n",
    "\t\t)\n",
    "\tdecoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\tprint(decoded_text.replace(\"\\n\", \"<|/n|>\"))\n",
    "\tmodel.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.818, Val loss 9.928\n",
      "Ep 1 (Step 000005): Train loss 8.065, Val loss 8.335\n",
      "Every effort moves you,,,,,,,,,,,,.<|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|>\n",
      "Ep 2 (Step 000010): Train loss 6.622, Val loss 7.051\n",
      "Ep 2 (Step 000015): Train loss 6.047, Val loss 6.600\n",
      "Every effort moves you, and,, and,,,,,,, and,.<|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|>\n",
      "Ep 3 (Step 000020): Train loss 5.586, Val loss 6.477\n",
      "Ep 3 (Step 000025): Train loss 5.523, Val loss 6.399\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and\n",
      "Ep 4 (Step 000030): Train loss 5.128, Val loss 6.366\n",
      "Ep 4 (Step 000035): Train loss 4.941, Val loss 6.366\n",
      "Every effort moves you a a to the a. Gisburn, and a. Gisburn. I had the of the of the of the of the of the of the of the of the of the of the of the of the of the. I had a\n",
      "Ep 5 (Step 000040): Train loss 4.340, Val loss 6.246\n",
      "Every effort moves you, with a, in the of the picture--as of the of the of the of the picture of his of the<|/n|><|/n|>\"I had been.<|/n|>\"Oh, in the donkey--and it was a little the man of the picture of\n",
      "Ep 6 (Step 000045): Train loss 3.967, Val loss 6.181\n",
      "Ep 6 (Step 000050): Train loss 3.451, Val loss 6.155\n",
      "Every effort moves you know the<|/n|>\"Oh, and.<|/n|><|/n|>\"Oh, and in a little: \"There, and in the<|/n|><|/n|><|/n|><|/n|>\"Oh, and I had been the donkey.<|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|>\n",
      "Ep 7 (Step 000055): Train loss 3.466, Val loss 6.195\n",
      "Ep 7 (Step 000060): Train loss 2.666, Val loss 6.134\n",
      "Every effort moves you know the picture.<|/n|><|/n|>\"I looked he was a little the last word.<|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|>\"I he was his pictures-c.<|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|>\n",
      "Ep 8 (Step 000065): Train loss 2.208, Val loss 6.141\n",
      "Ep 8 (Step 000070): Train loss 1.879, Val loss 6.228\n",
      "Every effort moves you know,\" was not that the picture.<|/n|><|/n|>\"I had the last word. Gisburn's an!<|/n|><|/n|>\"Oh, in the moment--as Jack himself, as he was his own the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075): Train loss 1.499, Val loss 6.230\n",
      "Ep 9 (Step 000080): Train loss 1.174, Val loss 6.250\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on that point I could have given Miss Croft the fact, with a Mrs. Gisburn's open countenance. \"It's his pictures with a \"strongest,\" she was\n",
      "Ep 10 (Step 000085): Train loss 0.901, Val loss 6.328\n",
      "Every effort moves you?\"<|/n|><|/n|>\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"<|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|><|/n|>He placed them at my elbow and as I turned, and down the room, when I\n",
      "Training completed in 0.19 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "\tmodel, train_loader, val_loader, optimizer, device,\n",
    "\tnum_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "\tstart_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epoches_seen, tokens_seen, train_losses, val_losses):\n",
    "\tfig, ax1 = plt.subplots(figsize=(5,3))\n",
    "\tax1.plot(epoches_seen, train_losses, label=\"Training loss\")\n",
    "\tax1.plot(epoches_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "\tax1.set_xlabel(\"Epochs\")\n",
    "\tax1.set_ylabel(\"Loss\")\n",
    "\tax1.legend(loc=\"upper right\")\t# 图例位置\n",
    "\tax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # 仅在 x 轴上显示整数标签\n",
    "\n",
    "\tax2 = ax1.twiny()\n",
    "\tax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "\tax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "\tfig.tight_layout()\t# 调整布局\n",
    "\tplt.savefig(\"loss-plot.pdf\")\n",
    "\tplt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Decoding strategies to control randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "\tmodel=model,\n",
    "\tidx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "\tmax_new_tokens=25,\n",
    "\tcontext_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1 Temperature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "# 用 torch.multinomial(probs, num_samples=1) 在概率词表中随机抽取词\n",
    "vocab = { \n",
    "\t\"closer\": 0,\n",
    "\t\"every\": 1, \n",
    "\t\"effort\": 2, \n",
    "\t\"forward\": 3,\n",
    "\t\"inches\": 4,\n",
    "\t\"moves\": 5, \n",
    "\t\"pizza\": 6,\n",
    "\t\"toward\": 7,\n",
    "\t\"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# input: every effort moves you\n",
    "# 假定输出结果为以下\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# The next generated token is then as follows:\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "# 依照概率用torch.multinomial进行1000次采样\n",
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123) # Manual seed for reproducibility\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 用 temperature scaling 控制采样的随机性\n",
    "- 将 logits 除以 temperature (temperature > 0)\n",
    "- \\> 1 时，采样更随机\n",
    "- \\<1 时，采样更确定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "\tscaled_logits = logits / temperature\n",
    "\treturn torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "temperatures = [1, 0.1, 5]\n",
    "\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: SIMSUN\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SIMSUN']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "# ax.set_title(\"三种不同缩放系数所导致的概率分布\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 当 temperature 趋近于0 时 torch.multinomial 的结果会接近 torch.argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "992 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "8 x toward\n",
      "0 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 x closer\n",
      "68 x every\n",
      "55 x effort\n",
      "223 x forward\n",
      "102 x inches\n",
      "50 x moves\n",
      "43 x pizza\n",
      "218 x toward\n",
      "88 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.2 Top-k\n",
    "\n",
    "- 选前k个概率最大的token\n",
    "\n",
    "- ~~Top-p~~ 前n个概率和大于p的token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "\tcondition=next_token_logits < top_logits[-1],\t# 将小于最小选择概率的值取为-inf\n",
    "\tinput=torch.tensor(float(\"-inf\")),\n",
    "\tother=next_token_logits\t# 不符合条件则不变\n",
    ")\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更高效的实现\n",
    "# 不保留梯度信息 但不需要梯度\n",
    "# 文本生成（采样）在训练之后 用来实际使用模型\n",
    "new_logits = torch.full_like( # create tensor containing -inf values\n",
    "next_token_logits, -torch.inf\n",
    ")   \n",
    "new_logits[top_pos] = next_token_logits[top_pos] # copy top k values into the -inf tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.3 Modifying the text generation function\n",
    "\n",
    "- 用temporary scaling 和 top-k 采样 修改 generate_text_simple 为generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\tfor _ in range(max_new_tokens):\n",
    "\t\tidx_cond = idx[:, -context_size:]\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tlogits = model(idx_cond)\n",
    "\t\tlogits = logits[:, -1, :]\n",
    "\n",
    "\t\tif top_k is not None:\n",
    "\t\t\ttop_logits, _ = torch.topk(logits, top_k)\n",
    "\t\t\tmin_val = top_logits[:, -1]\n",
    "\t\t\tlogits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(device), logits)\n",
    "\n",
    "\t\tif temperature > 0.0:\n",
    "\t\t\tlogits = logits / temperature\n",
    "\t\t\tprobs = torch.softmax(logits, dim=-1)\n",
    "\t\t\tidx_next = torch.multinomial(probs, num_samples=1)\n",
    "\t\telse:\n",
    "\t\t\tidx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "\n",
    "\t\tif idx_next == eos_id:\t# 若是终止符 则退出\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tidx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "\treturn idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you as terr what one of the pale yellow to face that with a curious.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model.to(device)\n",
    "\n",
    "token_ids = generate(\n",
    "\tmodel=model,\n",
    "\tidx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "\tmax_new_tokens=15,\n",
    "\tcontext_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "\ttop_k=25,\n",
    "\ttemperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 保存模型权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
    "model.eval();\t# 抑制该行代码的输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adam AdamW优化器 也有参数可保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "\t\"model_state_dict\": model.state_dict(),\n",
    "\t\"optimizer_state_dict\": optimizer.state_dict()\n",
    "\t},\n",
    "\t\"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 读取OpenAI的模型权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.1\n",
      "tqdm version: 4.62.3\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", version(\"tensorflow\"))\n",
    "print(\"tqdm version:\", version(\"tqdm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 12:50:53.422608: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-09 12:50:53.467064: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "Primary URL (https://openaipublic.blob.core.windows.net/gpt-2/models/124M/model.ckpt.data-00000-of-00001) failed. Attempting backup URL: https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OpenAI的模型中有bias 所以需要吧qkv_bias 设置为True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    \n",
    "    \n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you as far as the hand can go until the end of your turn unless something interrupts your control flow. As you may observe I\n"
     ]
    }
   ],
   "source": [
    "# 生成\n",
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every effort moves you as far as the hand can go until the end of your turn unless something interrupts your control flow. As you may observe I"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
