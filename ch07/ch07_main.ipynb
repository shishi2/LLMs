{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.23.0\n",
      "matplotlib version: 3.4.3\n",
      "tiktoken version: 0.7.0\n",
      "torch version: 2.4.1\n",
      "tqdm version: 4.62.3\n",
      "tensorflow version: 2.13.1\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "\t\"numpy\",       # PyTorch & TensorFlow dependency\n",
    "\t\"matplotlib\",  # Plotting library\n",
    "\t\"tiktoken\",    # Tokenizer\n",
    "\t\"torch\",       # Deep learning library\n",
    "\t\"tqdm\",        # Progress bar\n",
    "\t\"tensorflow\",  # For OpenAI's pretrained weights\n",
    "]\n",
    "for p in pkgs:\n",
    "\tprint(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "import urllib.request\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "\tif not os.path.exists(file_path):\n",
    "\t\twith urllib.request.urlopen(url) as response:\n",
    "\t\t\ttext_data = response.read().decode(\"utf-8\")\n",
    "\t\twith open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "\t\t\tfile.write(text_data)\n",
    "\n",
    "\twith open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "\t\tdata = json.load(file)\n",
    "\t\n",
    "\treturn data\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "\t\"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "\t\"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "# \"input\" 可以为空\n",
    "print(\"Another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "\tinstruction_text = (\n",
    "\t\tf\"Below is an instruction that describes a task. \"\n",
    "\t\tf\"Write a response that appropriately completes the request.\"\n",
    "\t\tf\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "\t)\n",
    "\n",
    "\tinput_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "\treturn instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Organizing data into training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "\tdef __init__(self, data, tokenizer):\n",
    "\t\tself.data = data\n",
    "\n",
    "\t\tself.encoded_texts = []\n",
    "\t\tfor entry in data:\n",
    "\t\t\tinstruction_plus_input = format(entry)\n",
    "\t\t\tresponse_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "\t\t\tfull_text = instruction_plus_input + response_text\n",
    "\t\t\tself.encoded_texts.append(tokenizer.encode(full_text))\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\treturn self.encoded_texts[index]\n",
    "\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each batch to have the same length (but different batches can have different lengths)\n",
    "def custom_collate_draft_1(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "\t\"\"\"\n",
    "\tinput\n",
    "\t\"\"\"\n",
    "\tbatch_max_length = max(len(item) + 1 for item in batch)\t# +1 保证所有序列末尾都有 <|endoftext|>\n",
    "\n",
    "\tinputs_lst = []\n",
    "\tfor item in batch:\n",
    "\t\tnew_item = item.copy()\n",
    "\t\tnew_item += [pad_token_id]\n",
    "\n",
    "\t\tpadded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "\t\tinputs = torch.tensor(padded[:-1])\t# ques -1?\n",
    "\t\tinputs_lst.append(inputs)\n",
    "\n",
    "\tinputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "\treturn inputs_tensor\t# 最终返回的长度 = batch中最长的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "\tinputs_1,\n",
    "\tinputs_2,\n",
    "\tinputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(batch, pad_token_ids=50256, device=\"cpu\"):\n",
    "\tbatch_max_length = max(len(item) + 1 for item in batch)\n",
    "\n",
    "\tinputs_lst, target_lst = [], []\n",
    "\tfor item in batch:\n",
    "\t\tnew_item = item.copy()\n",
    "\t\tnew_item += [pad_token_ids]\n",
    "\t\tpadded = new_item + [pad_token_ids] * (batch_max_length - len(new_item))\n",
    "\n",
    "\t\tinputs = torch.tensor(padded[:-1])\n",
    "\t\ttargets = torch.tensor(padded[1:])\n",
    "\t\tinputs_lst.append(inputs)\n",
    "\t\ttarget_lst.append(targets)\n",
    "\n",
    "\tinputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "\ttarget_tensor = torch.stack(target_lst).to(device)\n",
    "\treturn inputs_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 忽略多余的padding\n",
    "\n",
    "def custom_collate_fn(batch, pad_token_id=50256, ignore_index=-100, allowed_max_length=None, device=\"cpu\"):\n",
    "\tbatch_max_length = max(len(item) + 1 for item in batch)\n",
    "\n",
    "\tinputs_lst, target_lst = [], []\n",
    "\tfor item in batch:\n",
    "\t\tnew_item = item.copy()\n",
    "\t\tnew_item += [pad_token_id]\n",
    "\t\tpadded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "\t\tinputs = torch.tensor(padded[:-1])\n",
    "\t\ttargets = torch.tensor(padded[1:])\n",
    "\n",
    "\t\t# 只保留第一个<|endoftext|> 其他全改为-100\n",
    "\t\tmask = targets == pad_token_id\n",
    "\t\tindices = torch.nonzero(mask).squeeze()\t# 获得 50256 下标\n",
    "\t\tif indices.numel() > 1:\t# 多个 50256\n",
    "\t\t\ttargets[indices[1:]] = ignore_index\t# 之后全换成 -100\n",
    "\n",
    "\t\t# 可选择截断至最大序列长度\n",
    "\t\tif allowed_max_length is not None:\n",
    "\t\t\tinputs = inputs[:allowed_max_length]\n",
    "\t\t\ttargets = targets[:allowed_max_length]\n",
    "\n",
    "\t\tinputs_lst.append(inputs)\n",
    "\t\ttarget_lst.append(targets)\n",
    "\t\n",
    "\tinputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "\ttargets_tensor = torch.stack(target_lst).to(device)\n",
    "\n",
    "\treturn inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "\t[[-1.0, 1.0],  # 1st training example\n",
    "\t[-0.5, 1.5]]  # 2nd training example\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "\n",
    "\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "\t[[-1.0, 1.0],\n",
    "\t [-0.5, 1.5],\n",
    "\t [-0.5, 1.5]]  # New 3rd training example\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# 将3 换成 -100\n",
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\t# cross_entropy 中 的ignore_index默认=-100\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4 datdaloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)\t# 参数预填充pre-filled\t# curring!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "\ttrain_dataset,\n",
    "\tbatch_size=batch_size,\n",
    "\tcollate_fn=customized_collate_fn,\n",
    "\tshuffle=True,\n",
    "\tdrop_last=True,\n",
    "\tnum_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "\tval_dataset,\n",
    "\tbatch_size=batch_size,\n",
    "\tcollate_fn=customized_collate_fn,\n",
    "\tshuffle=False,\n",
    "\tdrop_last=False,\n",
    "\tnum_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "\ttest_dataset,\n",
    "\tbatch_size=batch_size,\n",
    "\tcollate_fn=customized_collate_fn,\n",
    "\tshuffle=False,\n",
    "\tdrop_last=False,\n",
    "\tnum_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 108]) torch.Size([8, 108])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 95]) torch.Size([8, 95])\n",
      "torch.Size([8, 90]) torch.Size([8, 90])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 107]) torch.Size([8, 107])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 102]) torch.Size([8, 102])\n",
      "torch.Size([8, 92]) torch.Size([8, 92])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 118]) torch.Size([8, 118])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 112]) torch.Size([8, 112])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 86]) torch.Size([8, 86])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 105]) torch.Size([8, 105])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 97]) torch.Size([8, 97])\n",
      "torch.Size([8, 118]) torch.Size([8, 118])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 106]) torch.Size([8, 106])\n",
      "torch.Size([8, 115]) torch.Size([8, 115])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 125]) torch.Size([8, 125])\n",
      "torch.Size([8, 104]) torch.Size([8, 104])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 107]) torch.Size([8, 107])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 101]) torch.Size([8, 101])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 112]) torch.Size([8, 112])\n",
      "torch.Size([8, 93]) torch.Size([8, 93])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 123]) torch.Size([8, 123])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 94]) torch.Size([8, 94])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 93]) torch.Size([8, 93])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 98]) torch.Size([8, 98])\n",
      "torch.Size([8, 114]) torch.Size([8, 114])\n",
      "torch.Size([8, 90]) torch.Size([8, 90])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 118]) torch.Size([8, 118])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 114]) torch.Size([8, 114])\n",
      "torch.Size([8, 114]) torch.Size([8, 114])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 94]) torch.Size([8, 94])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 117]) torch.Size([8, 117])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 109]) torch.Size([8, 109])\n",
      "torch.Size([8, 134]) torch.Size([8, 134])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 99]) torch.Size([8, 99])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 121]) torch.Size([8, 121])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 107]) torch.Size([8, 107])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "\tprint(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   90,     6,  8625,  2762, 10354,   705, 30003,  6525,   262,  6827,\n",
      "         1262,   257,   985,   576,  2637,    11,   705, 15414, 10354,   705,\n",
      "          464,  5156,   318,   845, 13779,  2637,    11,   705, 22915, 10354,\n",
      "          705,   464,  5156,   318,   355, 13779,   355,   257,  4936,  2637,\n",
      "           92,   198,   198, 21017, 18261,    25,   198,   464,  5156,   318,\n",
      "          355, 13779,   355,   257,  4936,    13, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256], device='cuda:0')\n",
      "tensor([    6,  8625,  2762, 10354,   705, 30003,  6525,   262,  6827,  1262,\n",
      "          257,   985,   576,  2637,    11,   705, 15414, 10354,   705,   464,\n",
      "         5156,   318,   845, 13779,  2637,    11,   705, 22915, 10354,   705,\n",
      "          464,  5156,   318,   355, 13779,   355,   257,  4936,  2637,    92,\n",
      "          198,   198, 21017, 18261,    25,   198,   464,  5156,   318,   355,\n",
      "        13779,   355,   257,  4936,    13, 50256,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])\n",
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Loading a pretrained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-18 08:29:11.950745: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-18 08:29:11.996110: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: ../ch05/gpt2/355M/checkpoint\n",
      "File already exists and is up-to-date: ../ch05/gpt2/355M/encoder.json\n",
      "File already exists and is up-to-date: ../ch05/gpt2/355M/hparams.json\n",
      "File already exists and is up-to-date: ../ch05/gpt2/355M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: ../ch05/gpt2/355M/model.ckpt.index\n",
      "File already exists and is up-to-date: ../ch05/gpt2/355M/model.ckpt.meta\n",
      "File already exists and is up-to-date: ../ch05/gpt2/355M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../ch05\")\n",
    "\n",
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "BASE_CONFIG = {\n",
    "\t\"vocab_size\": 50257,     # Vocabulary size\n",
    "\t\"context_length\": 1024,  # Context length\n",
    "\t\"drop_rate\": 0.0,        # Dropout rate\n",
    "\t\"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "\t\"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "\t\"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "\t\"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "\t\"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "setting, params = download_and_load_gpt2(model_size=model_size, models_dir=\"../ch05/gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)\n",
    "# Convert the active sentence to passive: 'The chef cooks the meal every day.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "# 只能重复回答\n",
    "response_text = (\n",
    "    generated_text[len(input_text):]\n",
    "    .replace(\"### Response:\", \"\")\n",
    "    .strip()\n",
    ")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 Finetuning the LLM on instruction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.891008424758911\n",
      "Validation loss: 2.7637264251708986\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.107, Val loss 2.012\n",
      "Ep 1 (Step 000005): Train loss 1.085, Val loss 0.988\n",
      "Ep 1 (Step 000010): Train loss 0.790, Val loss 0.887\n",
      "Ep 1 (Step 000015): Train loss 0.827, Val loss 0.859\n",
      "Ep 1 (Step 000020): Train loss 0.714, Val loss 0.841\n",
      "Ep 1 (Step 000025): Train loss 0.706, Val loss 0.808\n",
      "Ep 1 (Step 000030): Train loss 0.773, Val loss 0.794\n",
      "Ep 1 (Step 000035): Train loss 0.698, Val loss 0.769\n",
      "Ep 1 (Step 000040): Train loss 0.673, Val loss 0.766\n",
      "Ep 1 (Step 000045): Train loss 0.621, Val loss 0.754\n",
      "Ep 1 (Step 000050): Train loss 0.632, Val loss 0.738\n",
      "Ep 1 (Step 000055): Train loss 0.705, Val loss 0.721\n",
      "Ep 1 (Step 000060): Train loss 0.706, Val loss 0.708\n",
      "Ep 1 (Step 000065): Train loss 0.624, Val loss 0.697\n",
      "Ep 1 (Step 000070): Train loss 0.520, Val loss 0.694\n",
      "Ep 1 (Step 000075): Train loss 0.542, Val loss 0.698\n",
      "Ep 1 (Step 000080): Train loss 0.586, Val loss 0.681\n",
      "Ep 1 (Step 000085): Train loss 0.487, Val loss 0.666\n",
      "Ep 1 (Step 000090): Train loss 0.520, Val loss 0.663\n",
      "Ep 1 (Step 000095): Train loss 0.481, Val loss 0.661\n",
      "Ep 1 (Step 000100): Train loss 0.480, Val loss 0.646\n",
      "Ep 1 (Step 000105): Train loss 0.535, Val loss 0.647\n",
      "Ep 1 (Step 000110): Train loss 0.528, Val loss 0.647\n",
      "Ep 1 (Step 000115): Train loss 0.504, Val loss 0.638\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ### Response: The chef cooks the meal every day.<|endoftext|>The following is a list of all the animals that are classified as reptiles.  Animals classified as reptiles include: 1. Amphibians 2. Reptiles \n",
      "Ep 2 (Step 000120): Train loss 0.406, Val loss 0.636\n",
      "Ep 2 (Step 000125): Train loss 0.424, Val loss 0.647\n",
      "Ep 2 (Step 000130): Train loss 0.427, Val loss 0.640\n",
      "Ep 2 (Step 000135): Train loss 0.383, Val loss 0.638\n",
      "Ep 2 (Step 000140): Train loss 0.381, Val loss 0.637\n",
      "Ep 2 (Step 000145): Train loss 0.352, Val loss 0.638\n",
      "Ep 2 (Step 000150): Train loss 0.357, Val loss 0.637\n",
      "Ep 2 (Step 000155): Train loss 0.417, Val loss 0.644\n",
      "Ep 2 (Step 000160): Train loss 0.391, Val loss 0.644\n",
      "Ep 2 (Step 000165): Train loss 0.357, Val loss 0.641\n",
      "Ep 2 (Step 000170): Train loss 0.307, Val loss 0.636\n",
      "Ep 2 (Step 000175): Train loss 0.323, Val loss 0.639\n",
      "Ep 2 (Step 000180): Train loss 0.372, Val loss 0.613\n",
      "Ep 2 (Step 000185): Train loss 0.407, Val loss 0.623\n",
      "Ep 2 (Step 000190): Train loss 0.337, Val loss 0.617\n",
      "Ep 2 (Step 000195): Train loss 0.329, Val loss 0.613\n",
      "Ep 2 (Step 000200): Train loss 0.307, Val loss 0.607\n",
      "Ep 2 (Step 000205): Train loss 0.351, Val loss 0.595\n",
      "Ep 2 (Step 000210): Train loss 0.333, Val loss 0.597\n",
      "Ep 2 (Step 000215): Train loss 0.396, Val loss 0.606\n",
      "Ep 2 (Step 000220): Train loss 0.291, Val loss 0.616\n",
      "Ep 2 (Step 000225): Train loss 0.314, Val loss 0.622\n",
      "Ep 2 (Step 000230): Train loss 0.284, Val loss 0.622\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is a list of all the animals that are classified as birds.  Birds are mammals that are nocturnal and typically migrate at night. They typically\n",
      "Training completed in 0.89 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 2\n",
    "train_losses, val_losses, token_seen = train_model_simple(\n",
    "\tmodel, train_loader, val_loader, optimizer, device, num_epochs, eval_freq=5, eval_iter=5,\n",
    "\tstart_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_chapters import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, token_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 Extracting and saving responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "The car is as fast as a cheetah.\n",
      "The car is as fast as a cheetah.\n",
      "The car is as fast as a cheetah.\n",
      "The car is as fast as a cheetah.\n",
      "The car is as fast as a cheetah.\n",
      "The car is as fast as a cheetah.\n",
      "The car is as fast as a cheetah.\n",
      "The car is as fast as a cheetah.\n",
      "The car is as fast as a cheetah.\n",
      "The car is as fast as a cheetah.\n",
      "The car is as fast as a cheetah.\n",
      "The car is as fast as a cheetah.\n",
      "The car is as fast as a cheetah.\n",
      "The car is as fast as a cheetah.\n",
      "The car is as fast as a cheetah.\n",
      "The car is as fast as a cheetah.\n",
      "The car is as fast as a cheetah.\n",
      "The car is as fast as a cheetah.\n",
      "The car is as fast as a cheetah.\n",
      "The car is as fast as a cheetah.\n",
      "The car is\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> A thunderstorm is a type of cumulus cloud that typically forms over the surface of the Earth at a height of approximately 15 kilometers (9 miles).\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> \n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:44<00:00,  2.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\tinput_text = format_input(entry)\n",
    "\n",
    "\ttoken_ids = generate(\n",
    "\t\tmodel=model,\n",
    "\t\tidx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "\t\tmax_new_tokens=256,\n",
    "\t\tcontext_size=BASE_CONFIG[\"context_length\"],\n",
    "\t\teos_id=50256\n",
    "\t)\n",
    "\tgenerated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\tresponse_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "\ttest_data[i][\"model_response\"] = response_text\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a cheetah.\\nThe car is as fast as a cheetah.\\nThe car is as fast as a cheetah.\\nThe car is as fast as a cheetah.\\nThe car is as fast as a cheetah.\\nThe car is as fast as a cheetah.\\nThe car is as fast as a cheetah.\\nThe car is as fast as a cheetah.\\nThe car is as fast as a cheetah.\\nThe car is as fast as a cheetah.\\nThe car is as fast as a cheetah.\\nThe car is as fast as a cheetah.\\nThe car is as fast as a cheetah.\\nThe car is as fast as a cheetah.\\nThe car is as fast as a cheetah.\\nThe car is as fast as a cheetah.\\nThe car is as fast as a cheetah.\\nThe car is as fast as a cheetah.\\nThe car is as fast as a cheetah.\\nThe car is as fast as a cheetah.\\nThe car is as fast as a cheetah.\\nThe car is'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "# 保存模型\n",
    "\n",
    "import re\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL)}-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8 Evaluating"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
