{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.4.3\n",
      "numpy version: 1.22.4\n",
      "tiktoken version: 0.7.0\n",
      "torch version: 2.4.1\n",
      "tensorflow version: 2.13.1\n",
      "pandas version: 2.0.3\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",  # Plotting library\n",
    "\t\t\"numpy\",       # PyTorch & TensorFlow dependency\n",
    "\t\t\"tiktoken\",    # Tokenizer\n",
    "\t\t\"torch\",       # Deep learning library\n",
    "\t\t\"tensorflow\",  # For OpenAI's pretrained weights\n",
    "\t\t\"pandas\"       # Dataset loading\n",
    "\t   ]\n",
    "for p in pkgs:\n",
    "\tprint(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 微调的类型\n",
    "\n",
    "- instruction-finetuning\n",
    "\n",
    "- classification finetuning\n",
    "\n",
    "只能预测已知"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "\tif data_file_path.exists():\n",
    "\t\tprint(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "\t\treturn\n",
    "\n",
    "\t# Downloading the file\n",
    "\twith urllib.request.urlopen(url) as response:\n",
    "\t\twith open(zip_path, \"wb\") as out_file:\n",
    "\t\t\tout_file.write(response.read())\n",
    "\n",
    "\t# Unzipping the file\n",
    "\twith zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "\t\tzip_ref.extractall(extracted_path)\n",
    "\n",
    "\t# Add .tsv file extension\n",
    "\toriginal_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "\tos.rename(original_file_path, data_file_path)\n",
    "\tprint(f\"File downloaded and saved as {data_file_path}\")\n",
    "\t\n",
    "try:\n",
    "\tdownload_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "except (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\n",
    "\tprint(f\"Primary URL failed: {e}. Trying backup URL...\")\n",
    "\turl = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
    "\tdownload_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "45fd7cd3-63f1-4b27-b070-91c166296b75",
       "rows": [
        [
         "0",
         "ham",
         "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat..."
        ],
        [
         "1",
         "ham",
         "Ok lar... Joking wif u oni..."
        ],
        [
         "2",
         "spam",
         "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's"
        ],
        [
         "3",
         "ham",
         "U dun say so early hor... U c already then say..."
        ],
        [
         "4",
         "ham",
         "Nah I don't think he goes to usf, he lives around here though"
        ],
        [
         "5",
         "spam",
         "FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv"
        ],
        [
         "6",
         "ham",
         "Even my brother is not like to speak with me. They treat me like aids patent."
        ],
        [
         "7",
         "ham",
         "As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune"
        ],
        [
         "8",
         "spam",
         "WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only."
        ],
        [
         "9",
         "spam",
         "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030"
        ],
        [
         "10",
         "ham",
         "I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today."
        ],
        [
         "11",
         "spam",
         "SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info"
        ],
        [
         "12",
         "spam",
         "URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18"
        ],
        [
         "13",
         "ham",
         "I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times."
        ],
        [
         "14",
         "ham",
         "I HAVE A DATE ON SUNDAY WITH WILL!!"
        ],
        [
         "15",
         "spam",
         "XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL"
        ],
        [
         "16",
         "ham",
         "Oh k...i'm watching here:)"
        ],
        [
         "17",
         "ham",
         "Eh u remember how 2 spell his name... Yes i did. He v naughty make until i v wet."
        ],
        [
         "18",
         "ham",
         "Fine if thats the way u feel. Thats the way its gota b"
        ],
        [
         "19",
         "spam",
         "England v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/ú1.20 POBOXox36504W45WQ 16+"
        ],
        [
         "20",
         "ham",
         "Is that seriously how you spell his name?"
        ],
        [
         "21",
         "ham",
         "I‘m going to try for 2 months ha ha only joking"
        ],
        [
         "22",
         "ham",
         "So ü pay first lar... Then when is da stock comin..."
        ],
        [
         "23",
         "ham",
         "Aft i finish my lunch then i go str down lor. Ard 3 smth lor. U finish ur lunch already?"
        ],
        [
         "24",
         "ham",
         "Ffffffffff. Alright no way I can meet up with you sooner?"
        ],
        [
         "25",
         "ham",
         "Just forced myself to eat a slice. I'm really not hungry tho. This sucks. Mark is getting worried. He knows I'm sick when I turn down pizza. Lol"
        ],
        [
         "26",
         "ham",
         "Lol your always so convincing."
        ],
        [
         "27",
         "ham",
         "Did you catch the bus ? Are you frying an egg ? Did you make a tea? Are you eating your mom's left over dinner ? Do you feel my Love ?"
        ],
        [
         "28",
         "ham",
         "I'm back &amp; we're packing the car now, I'll let you know if there's room"
        ],
        [
         "29",
         "ham",
         "Ahhh. Work. I vaguely remember that! What does it feel like? Lol"
        ],
        [
         "30",
         "ham",
         "Wait that's still not all that clear, were you not sure about me being sarcastic or that that's why x doesn't want to live with us"
        ],
        [
         "31",
         "ham",
         "Yeah he got in at 2 and was v apologetic. n had fallen out and she was actin like spoilt child and he got caught up in that. Till 2! But we won't go there! Not doing too badly cheers. You? "
        ],
        [
         "32",
         "ham",
         "K tell me anything about you."
        ],
        [
         "33",
         "ham",
         "For fear of fainting with the of all that housework you just did? Quick have a cuppa"
        ],
        [
         "34",
         "spam",
         "Thanks for your subscription to Ringtone UK your mobile will be charged £5/month Please confirm by replying YES or NO. If you reply NO you will not be charged"
        ],
        [
         "35",
         "ham",
         "Yup... Ok i go home look at the timings then i msg ü again... Xuhui going to learn on 2nd may too but her lesson is at 8am"
        ],
        [
         "36",
         "ham",
         "Oops, I'll let you know when my roommate's done"
        ],
        [
         "37",
         "ham",
         "I see the letter B on my car"
        ],
        [
         "38",
         "ham",
         "Anything lor... U decide..."
        ],
        [
         "39",
         "ham",
         "Hello! How's you and how did saturday go? I was just texting to see if you'd decided to do anything tomo. Not that i'm trying to invite myself or anything!"
        ],
        [
         "40",
         "ham",
         "Pls go ahead with watts. I just wanted to be sure. Do have a great weekend. Abiola"
        ],
        [
         "41",
         "ham",
         "Did I forget to tell you ? I want you , I need you, I crave you ... But most of all ... I love you my sweet Arabian steed ... Mmmmmm ... Yummy"
        ],
        [
         "42",
         "spam",
         "07732584351 - Rodger Burns - MSG = We tried to call you re your reply to our sms for a free nokia mobile + free camcorder. Please call now 08000930705 for delivery tomorrow"
        ],
        [
         "43",
         "ham",
         "WHO ARE YOU SEEING?"
        ],
        [
         "44",
         "ham",
         "Great! I hope you like your man well endowed. I am  &lt;#&gt;  inches..."
        ],
        [
         "45",
         "ham",
         "No calls..messages..missed calls"
        ],
        [
         "46",
         "ham",
         "Didn't you get hep b immunisation in nigeria."
        ],
        [
         "47",
         "ham",
         "Fair enough, anything going on?"
        ],
        [
         "48",
         "ham",
         "Yeah hopefully, if tyler can't do it I could maybe ask around a bit"
        ],
        [
         "49",
         "ham",
         "U don't know how stubborn I am. I didn't even want to go to the hospital. I kept telling Mark I'm not a weak sucker. Hospitals are for weak suckers."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5572
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# subsample (undersample) ham = spam = 747\n",
    "\n",
    "def create_balanced_dataset(df):\n",
    "\tnum_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "\tham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "\tbalanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "\treturn balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "e9247156-f530-4664-867f-408d9b4f9052",
       "rows": [
        [
         "4307",
         "0",
         "Awww dat is sweet! We can think of something to do he he! Have a nice time tonight ill probably txt u later cos im lonely :( xxx."
        ],
        [
         "4138",
         "0",
         "Just got to  &lt;#&gt;"
        ],
        [
         "4831",
         "0",
         "The word \"Checkmate\" in chess comes from the Persian phrase \"Shah Maat\" which means; \"the king is dead..\" Goodmorning.. Have a good day..:)"
        ],
        [
         "4461",
         "0",
         "This is wishing you a great day. Moji told me about your offer and as always i was speechless. You offer so easily to go to great lengths on my behalf and its stunning. My exam is next friday. After that i will keep in touch more. Sorry."
        ],
        [
         "5440",
         "0",
         "Thank you. do you generally date the brothas?"
        ],
        [
         "4448",
         "0",
         "Please tell me you have some of that special stock you were talking about"
        ],
        [
         "2603",
         "0",
         "So when you gonna get rimac access "
        ],
        [
         "2219",
         "0",
         "Nice talking to you! please dont forget my pix :) i want to see all of you..."
        ],
        [
         "5219",
         "0",
         "Pls she needs to dat slowly or she will vomit more."
        ],
        [
         "1035",
         "0",
         "ZOE IT JUST HIT ME 2 IM FUCKING SHITIN MYSELF IL DEFO TRY MY HARDEST 2 CUM 2MOROW LUV U MILLIONS LEKDOG"
        ],
        [
         "3515",
         "0",
         "I always chat with you. In fact i need money can you raise me?"
        ],
        [
         "3115",
         "0",
         "Yes watching footie but worried we're going to blow it - Phil Neville?"
        ],
        [
         "3553",
         "0",
         "Lol u still feeling sick?"
        ],
        [
         "5264",
         "0",
         "Storming msg: Wen u lift d phne, u say \"HELLO\" Do u knw wt is d real meaning of HELLO?? . . . It's d name of a girl..! . . . Yes.. And u knw who is dat girl?? \"Margaret Hello\" She is d girlfrnd f Grahmbell who invnted telphone... . . . . Moral:One can 4get d name of a person, bt not his girlfrnd... G o o d n i g h t . . .@"
        ],
        [
         "5539",
         "0",
         "Just sleeping..and surfing"
        ],
        [
         "2008",
         "0",
         "Hi here. have birth at on the  to  at 8lb 7oz. Mother and baby doing brilliantly."
        ],
        [
         "291",
         "0",
         "Hey you told your name to gautham ah?"
        ],
        [
         "3305",
         "0",
         "IM GONNAMISSU SO MUCH!!I WOULD SAY IL SEND U A POSTCARD BUTTHERES ABOUTAS MUCH CHANCE OF MEREMEMBERIN ASTHERE IS OFSI NOT BREAKIN HIS CONTRACT!! LUV Yaxx"
        ],
        [
         "3812",
         "0",
         "Excellent! Wish we were together right now!"
        ],
        [
         "4175",
         "0",
         "And pls pls drink plenty plenty water"
        ],
        [
         "4937",
         "0",
         "K..k.:)congratulation .."
        ],
        [
         "3986",
         "0",
         "Whatever, juliana. Do whatever you want."
        ],
        [
         "1859",
         "0",
         "Sir, i am waiting for your call."
        ],
        [
         "4495",
         "0",
         "Man this bus is so so so slow. I think you're gonna get there before me"
        ],
        [
         "5387",
         "0",
         "I will be gentle baby! Soon you will be taking all  &lt;#&gt;  inches deep inside your tight pussy..."
        ],
        [
         "1987",
         "0",
         "S..antha num corrct dane"
        ],
        [
         "4812",
         "0",
         "E admin building there? I might b slightly earlier... I'll call u when i'm reaching..."
        ],
        [
         "1906",
         "0",
         "There're some people by mu, I'm at the table by lambda"
        ],
        [
         "5124",
         "0",
         "He is impossible to argue with and he always treats me like his sub, like he never released me ... Which he did and I will remind him of that if necessary"
        ],
        [
         "1280",
         "0",
         "Waiting 4 my tv show 2 start lor... U leh still busy doing ur report?"
        ],
        [
         "3019",
         "0",
         "I didn't get the second half of that message"
        ],
        [
         "4617",
         "0",
         "Ü called dad oredi..."
        ],
        [
         "3434",
         "0",
         "Christmas is An occasion that is Celebrated as a Reflection of UR... Values..., Desires..., Affections...&amp; Traditions.... Have an ideal Christmas..."
        ],
        [
         "3052",
         "0",
         "Awesome question with a cute answer: Someone asked a boy \"how is ur life?\" . . He smiled &amp; answered: . . \"She is fine!\" Gudnite"
        ],
        [
         "2813",
         "0",
         "Say this slowly.? GOD,I LOVE YOU &amp; I NEED YOU,CLEAN MY HEART WITH YOUR BLOOD.Send this to Ten special people &amp; u c miracle tomorrow, do it,pls,pls do it..."
        ],
        [
         "2645",
         "0",
         "My friends use to call the same."
        ],
        [
         "774",
         "0",
         "I wil be there with in  &lt;#&gt;  minutes. Got any space"
        ],
        [
         "2904",
         "0",
         "Tell me pa. How is pain de."
        ],
        [
         "1102",
         "0",
         "Yeah go on then, bored and depressed sittin waitin for phone to ring... Hope the wind drops though, scary"
        ],
        [
         "3431",
         "0",
         "You've always been the brainy one."
        ],
        [
         "3234",
         "0",
         "Height of recycling: Read twice- People spend time for earning money and the same money is spent for spending time!;-) Good morning.. keep smiling:-)"
        ],
        [
         "5001",
         "0",
         "Well its not like you actually called someone a punto. That woulda been worse."
        ],
        [
         "4893",
         "0",
         "Miserable. They don't tell u that the side effects of birth control are massive gut wrenching cramps for the first 2 months. I didn't sleep at all last night."
        ],
        [
         "4850",
         "0",
         "either way works for me. I am  &lt;#&gt;  years old. Hope that doesnt bother you."
        ],
        [
         "411",
         "0",
         "Come by our room at some point so we can iron out the plan for this weekend"
        ],
        [
         "23",
         "0",
         "Aft i finish my lunch then i go str down lor. Ard 3 smth lor. U finish ur lunch already?"
        ],
        [
         "1825",
         "0",
         "Sent me ur email id soon"
        ],
        [
         "4478",
         "0",
         "Oh :-)only 4 outside players allowed to play know"
        ],
        [
         "1883",
         "0",
         "Sorry, I can't help you on this."
        ],
        [
         "287",
         "0",
         "Ok.."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 1494
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分数据集\n",
    "\n",
    "def random_split(df, train_frac, validation_frac):\n",
    "\tdf = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "\ttrain_end = int(len(df) * train_frac)\n",
    "\tvalidation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "\ttrain_df = df[:train_end]\n",
    "\tvalidation_df = df[train_end:validation_end]\n",
    "\ttest_df = df[validation_end:]\n",
    "\n",
    "\treturn train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 data loader\n",
    "\n",
    "- 数据长短不一 若是要用多个样本批量训练\n",
    "- truncat 截断\n",
    "- padding 填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "# padding\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "\tdef __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "\t\tself.data = pd.read_csv(csv_file)\n",
    "\n",
    "\t\t# Pre-tokenize texts\n",
    "\t\tself.encoded_texts = [\n",
    "\t\t\ttokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "\t\t]\n",
    "\n",
    "\t\tif max_length is None:\n",
    "\t\t\tself.max_length = self._longest_encoded_length()\n",
    "\t\telse:\n",
    "\t\t\tself.max_length = max_length\n",
    "\t\t\t# 截断比max_length长的\n",
    "\t\t\tself.encoded_texts = [\n",
    "\t\t\t\tencoded_text[:self.max_length] for encoded_text in self.encoded_texts\n",
    "\t\t\t]\n",
    "\t\t\n",
    "\t\t# padding\n",
    "\t\tself.encoded_texts = [\n",
    "\t\t\tencoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "\t\t\tfor encoded_text in self.encoded_texts\n",
    "\t\t]\n",
    "\t\n",
    "\tdef __getitem__(self, index):\n",
    "\t\tencoded = self.encoded_texts[index]\n",
    "\t\tlabel = self.data.iloc[index][\"Label\"]\n",
    "\t\treturn (\n",
    "\t\t\ttorch.tensor(encoded, dtype=torch.long),\n",
    "\t\t\ttorch.tensor(label, dtype=torch.long)\n",
    "\t\t)\n",
    "\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.data)\n",
    "\t\n",
    "\tdef _longest_encoded_length(self):\n",
    "\t\tmax_length = 0\n",
    "\t\tfor encoded_text in self.encoded_texts:\n",
    "\t\t\tencoded_length = len(encoded_text)\n",
    "\t\t\tif encoded_length > max_length:\n",
    "\t\t\t\tmax_length = encoded_length\n",
    "\t\treturn max_length\n",
    "\t\t# return max(len(encoded_text) for encoded_text in self.encoded_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "\tcsv_file=\"train.csv\",\n",
    "\tmax_length=None,\n",
    "\ttokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "\tcsv_file=\"validation.csv\",\n",
    "\tmax_length=train_dataset.max_length,\n",
    "\ttokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "\tcsv_file=\"test.csv\",\n",
    "\tmax_length=train_dataset.max_length,\n",
    "\ttokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "\tdataset=train_dataset,\n",
    "\tbatch_size=batch_size,\n",
    "\tshuffle=True,\n",
    "\tnum_workers=num_workers,\n",
    "\tdrop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "\tdataset=val_dataset,\n",
    "\tbatch_size=batch_size,\n",
    "\tnum_workers=num_workers,\n",
    "\tdrop_last=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "\tdataset=test_dataset,\n",
    "\tbatch_size=batch_size,\n",
    "\tnum_workers=num_workers,\n",
    "\tdrop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "\tpass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 初始化权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "\t\"vocab_size\" : 50257,\n",
    "\t\"context_length\" : 1024,\n",
    "\t\"drop_rate\" : 0.0,\n",
    "\t\"qkv_bias\" : True\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "\t\"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "\t\"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "\t\"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "\t\"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "\tf\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "\tf\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "\tf\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/liuxianguo2/linshuo/LLMs/ch06', '/opt/conda/lib/python38.zip', '/opt/conda/lib/python3.8', '/opt/conda/lib/python3.8/lib-dynload', '', '/opt/conda/lib/python3.8/site-packages', '/opt/conda/lib/python3.8/site-packages/IPython/extensions', '/root/.ipython', '..', '..', '..', '..']\n",
      "File already exists and is up-to-date: ../ch05/gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: ../ch05/gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: ../ch05/gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: ../ch05/gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: ../ch05/gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: ../ch05/gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: ../ch05/gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "print(sys.path)\n",
    "from ch05.gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"../ch05/gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n",
      "\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import generate_text_simple, token_ids_to_text, text_to_token_ids\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "\tmodel=model,\n",
    "\tidx=text_to_token_ids(text_1, tokenizer),\n",
    "\tmax_new_tokens=15,\n",
    "\tcontext_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))\n",
    "print()\n",
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "\t\"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "\t\" 'You are a winner you have been specially\"\n",
    "\t\" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "\tmodel=model,\n",
    "\tidx=text_to_token_ids(text_2, tokenizer),\n",
    "\tmax_new_tokens=50,\n",
    "\tcontext_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))\n",
    "# Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
    "\n",
    "# The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Adding a classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- replace and finetune the output layers\n",
    "- 冻结模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "\tparam.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更换最后的输出层\n",
    "\n",
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解冻最后的一个transformer和Layer_norm\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    "\tparam.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "\tparam.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# 输入不变\n",
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "# 输出只有2维\n",
    "with torch.no_grad():\n",
    "\toutputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "# 最后一个token的输出\n",
    "# 根据所有已知信息得出的 不经过mask\n",
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 loss & acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "概率:  tensor([[    0.0005,     0.9995]])\n",
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probs = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"概率: \", probs)\n",
    "# 也可不用 softmax 选最大的输出就行\n",
    "label = torch.argmax(probs)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "\tmodel.eval()\n",
    "\tcorrect_predictions, num_examples = 0, 0\n",
    "\t\n",
    "\tif num_batches is None:\n",
    "\t\tnum_batches = len(data_loader)\n",
    "\telse:\n",
    "\t\tnum_batches = min(num_batches, len(data_loader))\n",
    "\t\n",
    "\tfor i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "\t\tif i < num_batches:\n",
    "\t\t\tinput_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\t\t\t\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tlogits = model(input_batch)[:, -1, :]\n",
    "\t\t\tpredicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "\t\t\tnum_examples += predicted_labels.shape[0]\n",
    "\t\t\tcorrect_predictions += (predicted_labels == target_batch).sum().item()\n",
    "\t\telse:\n",
    "\t\t\tbreak\n",
    "\treturn correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# torch.cuda.empty_cache()\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "\tinput_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\tlogits = model(input_batch)[:, -1, :]\n",
    "\tloss = torch.nn.functional.cross_entropy(logits, target_batch)\t# 自动处理softmax和on-hot标签的转换\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as in chapter 5\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "\ttotal_loss = 0.\n",
    "\tif len(data_loader) == 0:\n",
    "\t\treturn float(\"nan\")\n",
    "\telif num_batches is None:\n",
    "\t\tnum_batches = len(data_loader)\n",
    "\telse:\n",
    "\t\t# Reduce the number of batches to match the total number of batches in the data loader\n",
    "\t\t# if num_batches exceeds the number of batches in the data loader\n",
    "\t\tnum_batches = min(num_batches, len(data_loader))\n",
    "\tfor i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "\t\tif i < num_batches:\n",
    "\t\t\tloss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "\t\t\ttotal_loss += loss.item()\n",
    "\t\telse:\n",
    "\t\t\tbreak\n",
    "\treturn total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.193\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "\ttrain_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "\tval_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\ttest_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.706\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "\ttrain_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "\tval_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\ttest_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 Finetuning the model on supervised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as chapter 5\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "\tmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\ttrain_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "\t\tval_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "\tmodel.train()\n",
    "\treturn train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall the same as `train_model_simple` in chapter 5\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "\t\t\t\t\t\t\teval_freq, eval_iter):\n",
    "\t# Initialize lists to track losses and examples seen\n",
    "\ttrain_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\texamples_seen, global_step = 0, -1\n",
    "\n",
    "\t# Main training loop\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\tmodel.train()  # Set model to training mode\n",
    "\n",
    "\t\tfor input_batch, target_batch in train_loader:\n",
    "\t\t\toptimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "\t\t\tloss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "\t\t\tloss.backward() # Calculate loss gradients\n",
    "\t\t\toptimizer.step() # Update model weights using loss gradients\n",
    "\t\t\texamples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "\t\t\tglobal_step += 1\n",
    "\n",
    "\t\t\t# Optional evaluation step\n",
    "\t\t\tif global_step % eval_freq == 0:\n",
    "\t\t\t\ttrain_loss, val_loss = evaluate_model(\n",
    "\t\t\t\t\tmodel, train_loader, val_loader, device, eval_iter)\n",
    "\t\t\t\ttrain_losses.append(train_loss)\n",
    "\t\t\t\tval_losses.append(val_loss)\n",
    "\t\t\t\tprint(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "\t\t\t\t\t  f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "\t\t# Calculate accuracy after each epoch\n",
    "\t\ttrain_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "\t\tval_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "\t\tprint(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "\t\tprint(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "\t\ttrain_accs.append(train_accuracy)\n",
    "\t\tval_accs.append(val_accuracy)\n",
    "\n",
    "\treturn train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
      "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
      "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
      "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
      "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
      "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
      "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
      "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 0.42 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "\tmodel, train_loader, val_loader, optimizer, device,\n",
    "\tnum_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.21%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 95.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 Using the LLM as a spam classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "\tmodel.eval()\n",
    "\n",
    "\tinput_ids = tokenizer.encode(text)\n",
    "\tsupported_context_length = model.pos_emb.weight.shape[0]\n",
    "\n",
    "\tinput_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\tassert max_length is not None, (\n",
    "\t\t\"必须指定max_length 若要使用完整的模型上下文context\"\n",
    "\t\t\"pass max_length=model.pos_emb.weight.shape[0].\"\n",
    "\t)\n",
    "\tassert max_length <= supported_context_length, (\n",
    "\t\tf\"max_length ({max_length}) exceeds model's supported context length ({supported_context_length}).\"\n",
    "\t)\n",
    "\t# 以下实现更优秀\n",
    "\t# max_len = min(max_length,supported_context_length) if max_length else supported_context_length\n",
    "\t# input_ids = input_ids[:max_len]\n",
    "\n",
    "\t# padding\n",
    "\tinput_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "\tinput_tensor = torch.tensor(input_ids, device=device).unsqueeze(0)\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tlogits = model(input_tensor)[:, -1, :]\n",
    "\tpredicted_label = torch.argmax(logits, dim=-1)\n",
    "\n",
    "\treturn \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "text_2 = (\n",
    "\t\"点击以下按钮领取两万美元，你还在等什么？\"\n",
    "\t# \"click the button below to receive $20,000, what are you waitting for ?\"\n",
    ")\n",
    "\n",
    "text_2 = (\n",
    "\t# \"点击以下按钮领取两万美元\"\n",
    "\t\"click the button below to receive $20,000\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存权重\n",
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device, weights_only=True)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
